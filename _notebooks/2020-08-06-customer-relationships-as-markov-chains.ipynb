{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Customer Relationships as Markov Chains\n",
    "> Overview of the work from P. E. Pfeifer and R. L. Carraway\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/markov.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "On this note I want to explore the work presented in the article [\"Modelling customer relationships as Markov Chains\" from P. E. Pfeifer and R. L. Carraway (2000)](http://web.stanford.edu/class/msande121/Links/crmmodelingmarkov.pdf). \n",
    "\n",
    "Lets consider a business with non-contractual relations with their customers, it can be for instance a shop selling products.   The business spends money on direct marketing campaings that aim to make customers who have purchased previously purchase again.\n",
    "\n",
    "As the famous quote says \"Half the money I spend on advertising is wasted; the trouble is I don't know which half.\" (John Wanamake). The purpose of the work analized here is to model the customer purchasing behavior in the scenario depicted above, with the objective of optimizing the direct marketing spend of the business.  \n",
    "\n",
    "The authors start by presenting a simple toy scenario to illustrate their ideas.    I will present below this simple scenario, with some modifications to make things more concrete.   But before doing this, I will like to introduce briefly two concepts that we will be using: Customer Lifetime Value and Markov Chains.\n",
    "\n",
    "After presenting the toy model, we will discuss a general formulation of the model and then we will look at a more realistic application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Lifetime Value\n",
    "\n",
    "Customer Lifetime Value, which we will be referring to as Lifetime Value (LV), is a very important concept for marketing.    LV is a **prediction** of the profit attributed to the **future** relationship with a customer. \n",
    "\n",
    "This short definition tells us that LV is the expected future profit from a customer relationship and as such it needs to be a prediction, in other words it will depend on some model and assumptions.  Being a forward looking metric, its useful as it allows managers to focus on customer that will be more profitable in the long term.  LV can also be regarded as an upper limit on the cost-per-acquisition of new customers.\n",
    "\n",
    "Other definitions mention that LV represents the present value of the projected future cash flows attributed to a customer relationship, and by this they are taking into account the time-value of money.   \n",
    "\n",
    "When modelling the LV we need to consider wether we are dealing with a contractual setting (for example a subscription based business model) or a non-contractual setting (like a shop selling items online).  The models used will differ considerably in both cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains\n",
    "\n",
    "When we observe a sequence of chance experiments, the probabilities for the outcomes of the next experiment can depend in general on all of the past outcomes.  Here we focus on a special class of processes that present a simpler dependence between experiments.    Processes for which the outcome of a given experiment can only affect the outcome of the next experiment are known as Markov Chains.  This naming comes from A. A. Markov, who studied the mathematical properties of these processes.  An introduction to Markov Chains can be found on this book for example *Grinstead and Snellâ€™s Introduction to Probability*.\n",
    "\n",
    "\n",
    "We specify a Markov Chain in terms of a set of states $S = \\{s_1, s_2, \\ldots s_n\\}$.  The system will move among this states in discrete steps.   When the chain is in the state $s_i$, it will move to the state $s_j$ at the next step with a probability $p_{ij}$. We call $p_{ij}$ transition probabilities and they can be written in matrix form.\n",
    "\n",
    "Markov chains are also depicted usually in terms of a diagram, below we show a simple Markov chain \n",
    "\n",
    "<img src=\"../images/lily.png\" width=\"500\">\n",
    "\n",
    "The frog can be in two states (left lily or right lily) and the numbers depict the associated transition probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy model\n",
    "\n",
    "Consider a shop that sells one product at a price $NC$ (in the notation of the authors, $NC$ is the net contribution to the company profits).    Assume for simplicity that customers cannot buy more than one unit per month from this shop.     Every month the company will spend $M$ in marketing for each customer unless its last purchase was 5 months ago or longer, when this happens the shop considers the relation with the customer finished.       \n",
    "\n",
    "We will be characterizing customers in terms of states. In this case, customer states will be determined by the their recency, the number of months since their last purchase.     Lets consider a concrete case:  We have a new customer that purchases in january.   In february we will say that this customer has a recency $r=1$, as one month as passed.  On march, he will continue having recency $r=1$ if he bought again in february, otherwise he will have recency $r=2$.  If the customer has not bought anything by june, he will have recency $r=5$ by then and we will declare him inactive at that point.    \n",
    "\n",
    "In the toy scenario we analyze, we will assume that the probability that a customer will purchase again in a given month only depends on its recency.       Direct marketers have observed that recency plays a very important role in determining the probability that a customer will purchase again, so though we analyze a very simplified scenario it is not pointless.   \n",
    "\n",
    "\n",
    "The system we are describing is very special, in the sense that the next state of the customer is determined only by its current state indepently of how he arrived to that state.  For instance, a customer with recency $r=3$ can either purchase again or not.  The probability he purchases again in that month only depends on its recency.   If he purchases again his next state is $r=1$, else his next state is $r=4$. This is what people calls the Markov property.  \n",
    "\n",
    "If we draw this system as a diagram it would look like this\n",
    "\n",
    "\n",
    "<img src=\"../images/markov.png\" width=\"500\">\n",
    "\n",
    "The arrows represent the possible paths and $p_r$ represents the probability that a customer with recency $r$ will purchase again.   In matrix form, the previous diagram can be written as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{P} = \n",
    "\\begin{pmatrix}\n",
    "p_1 & 1 - p_{1} & 0 & 0 & 0 \\\\\n",
    "p_2 & 0 & 1- p_2 & 0 & 0\\\\\n",
    "p_3  & 0  & 0  & 1-p_3 & 0 \\\\\n",
    "p_4  & 0 & 0 & 0 & 1-p_4 \\\\\n",
    "0  & 0 & 0 & 0& 1 \n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Note that the $[\\mathbf{P}]_{5,5}$ entry is $1$ as the customer will never purchase back again in this state.  Ultimately, we would like to estimate the lifetime value of our customers.   For this, we need to consider the cash-flows associated to each customer state.   This information is contained in the vector $\\mathbf{R}$ \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{R} = \n",
    "\\begin{pmatrix}\n",
    "NC - M \\\\\n",
    "-M \\\\\n",
    "-M \\\\\n",
    "-M \\\\\n",
    "0 \n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Which can be interpreted as follows, when the customer goes to state $r=1$, he has just purchased one item (bringing $+ NC$ in profits) and will cost $M$ in marketing spenditures in that month.   For recency $r=2,3,4$ the customer costs $M$ in marketing while for $r=5$ the shop already declared the customer inactive. \n",
    "\n",
    "With all the information we have so far, we can estimate the Lifetime Value (LV) of a customer $T$ months after its first purchase. Assume that we have a customer making its first purchase in a given month. The LV at $T$ months is then given by \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{LV} = [\\sum_{t=0}^{T} \\mathbf{P}^{\\,t}]_{1i} \\, R_{i}\n",
    "\\end{equation*}\n",
    "\n",
    "Here we use Einstein summation convention of contracted indices. We can examine the first two terms.  The first term is simply $NC - M$ corresponding to the first purchase and the associated first marketing spenditure on that customer.  The second term is $(p_1) (NC - M )  - (1-p_1) M  $, which accounts for the two possible scenarios at this stage (he buys again or not).  This hopefully makes the previous formula more clear.   Note that $[\\mathbf{P}^{\\,t}]_{ij}$ is the probability that the customer will be at recency $j$ at the end of month $t$\n",
    "given that he started at recency $i$. Thats one of the nice things of the Markov property, we can know what happens after several steps by simply taking powers of the one-step evolution matrix.    \n",
    "\n",
    "Notice that in all the discussion I am not including the effects of the time-value of money as the authors do, as I dont think they are crucial for the dicussion and then I can deal with simpler formulas. \n",
    "\n",
    "We can take the previous formula for the LV and consider the limit $T \\to \\infty$.  In this case the formula becomes\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{LV} = [(1- \\mathbf{P})^{-1}]_{1i} \\, R_{i}\n",
    "\\end{equation*}\n",
    "\n",
    "where we have used Taylor expansion for the inverse matrix of $1- \\mathbf{P}$.   \n",
    "\n",
    "\n",
    "We have a Markov Chain with five states $\\{ s_1, s_2, \\ldots, s_5 \\}$ for the different recency values.   The last state $r=5$ is known as an absortive state because it is impossible to leave it.  Furthermore we are dealing with an absortive Markov Chain because its possible to go from all states to the absortive state.   Absortive Markov Chains have some special properties we will be using next. \n",
    "\n",
    "Note that we can write our matrix $\\mathbf{P}$ in block form as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{P} = \n",
    "\\begin{pmatrix}\n",
    "Q_{4 \\times 4}& A_{4 \\times 1}  \\\\\n",
    "0_{1 \\times 4} & 1\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "$Q$ encodes transition probabilities among transient states and $A$ represents absortive probabilities.  Taking also into account also that $R_{5} = 0$, we can write \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{LV} =  \\sum_{i=1}^{4} [(1- \\mathbf{Q})^{-1}]_{1i} \\, R_{i}\n",
    "\\end{equation*}\n",
    "\n",
    "At this stage we can resort to the properties of absortive Markov Chains, which tell us that $1- \\mathbf{Q}$ has an inverse given by \n",
    "\n",
    "\\begin{equation*}\n",
    "N \\equiv (1 - Q)^{-1} =  1 + Q + Q^2 + \\cdots\n",
    "\\end{equation*}\n",
    "\n",
    "$N$ is called the fundamental matrix of $\\mathbf{P}$.  We also know that $\\lim_{n \\to \\infty} Q^n  = 0$, meaning that the process will always be absorbed at some point.    \n",
    "\n",
    "Having a model of the customer LV, we can optimize the marketing campaign according to this value.   \n",
    "Lets consider some specific values for the different model parameters: $NC= 40$, $M=4$.  lets also consider a situation where we observe $p_1=0.3$, $p_2=0.2$, $p_3=0.15$, $p_4=0.05$.   In this case we obtain $\\mathrm{LV} = 64.25$.   Now, lets imagine the firm tries a different approach where they close the relation with the customers a t $r \\geq 4$ (this implies $R_4 = 0$), and this has the effect of decreasing $p_4$ down to $0.01$.    In this case we get $\\mathrm{LV} = 65.7$.   So we see how we can choose among different marketing campaign settings by optimizing on the LV. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â General Formulation\n",
    "\n",
    "In this section we will present a general model for customer relationships as Markov Chains.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Example\n",
    "\n",
    "We will apply the general formulation developed previously to a concrete scenario.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
